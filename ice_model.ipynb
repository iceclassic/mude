{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import time\n",
    "\n",
    "def decimal_time(t, direction='to_decimal'):\n",
    "    \"\"\" Convert time object to decimal and decimal to time object depending on the direction given\n",
    "\n",
    "    Arguments:\n",
    "        t : datetime object if direction is 'to_decimal'\n",
    "            float if direction is 'to_hexadecimal'\n",
    "    Returns:\n",
    "        float if direction is 'to_decimal'\n",
    "        datetime object if direction is 'to_hexadecimal`\n",
    "    \"\"\"\n",
    "\n",
    "    if direction =='to_decimal':\n",
    "        return t.hour+t.minute/60\n",
    "    elif direction=='to_hexadecimal':\n",
    "        hours=int(t)\n",
    "        minutes=int(t-hours)*60\n",
    "        return time(hours,minutes)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid direction, choose 'to_decimal'or 'to_hexadecimal'\")\n",
    "    \n",
    "\n",
    "class IceModel(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Simple model that fits trend to historic data to extrapolate future break up date.\n",
    "\n",
    "    Only considers previous break up dates. \n",
    "\n",
    "\n",
    "    The model compute the date and day separately\n",
    "\n",
    "    METHODS:\n",
    "        Polifit: Polinomic fit\n",
    "        Distribtution: Fits number of distributions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,df):\n",
    "        \"\"\"Initializing object with DataFrame with break up dates.\n",
    "        Args:\n",
    "        df(_pandas DataFrame_): Specific format and column names are hard coded based on the file `BreakUpTime.csv` \n",
    "        \"\"\"\n",
    "        self.df=df.copy()\n",
    "        self._predicted_day_of_break_up=None  # the object is initialize as having no prediction\n",
    "        self._predicted_time_of_break_up=None\n",
    "\n",
    "\n",
    "# Time of break up\n",
    "    @property\n",
    "    def date_time(self):\n",
    "        return  pd.to_datetime(self.df[['Year', 'Month', 'Day', 'Hour', 'Minute']])\n",
    "    \n",
    "    @property\n",
    "    def time(self):\n",
    "        return self.date_time.dt.time\n",
    "    @property\n",
    "    def decimal_time(self):\n",
    "        return self.time.apply(lambda t: decimal_time(t,direction='to_decimal'))\n",
    "   \n",
    "    @property\n",
    "    def fit_time(self):\n",
    "        return self.fit_time\n",
    "    @fit_time.setter\n",
    "    def fit_time(self,value):   # revisar con test\n",
    "        self.fit_time=value\n",
    "# day of break up\n",
    "    @property\n",
    "    def day_of_year(self):\n",
    "        return self.date_time.dt.dayofyear.tolist()\n",
    "   \n",
    "    @property\n",
    "    def year(self):\n",
    "        return self.date_time.dt.year\n",
    "   \n",
    "    @property\n",
    "    def fit_day_of_year(self):\n",
    "        return self._fit_day_of_year\n",
    "    @fit_day_of_year.setter\n",
    "    def fit_day_of_year(self,value):\n",
    "        self._fit_day_of_year=value\n",
    "   \n",
    "    @property\n",
    "    def predicted_day_of_break_up(self):\n",
    "        if self.predicted_day_of_break_up is None:\n",
    "            raise ValueError(\" Predicton of day of break up has not been made\")\n",
    "        return self.get_predicted_day\n",
    "    @predicted_day_of_break_up.setter\n",
    "    def predicted_day_of_break_up(self,value):\n",
    "        self._predicted_day_of_break_up=value\n",
    "    \n",
    "    @property\n",
    "    def predicted_time_of_break_up(self):\n",
    "        if self.predicted_time_of_break_up is None:\n",
    "            raise ValueError(\" Predicton of time of break up has not been made\")\n",
    "        return self.get_predicted_time\n",
    "    @predicted_time_of_break_up.setter\n",
    "    def predicted_dtime_of_break_up(self,value):\n",
    "        self._predicted_time_of_break_up=value\n",
    "   \n",
    "    @property\n",
    "    def prediction(self):\n",
    "        if self._prediction is None:\n",
    "            raise ValueError(\" Predicton of  date and time of break up has not been made\")\n",
    "        return self.get_prediction\n",
    "    @predicted_time_of_break_up.setter\n",
    "    def predicted_dtime_of_break_up(self,value):\n",
    "        self._predicted_time_of_break_up=value\n",
    "\n",
    "\n",
    "   # General stuff \n",
    "   \n",
    "       \n",
    "    # methods\n",
    "    def polyfit(self,x_property,y_property,degree,norm_order=2,print_eq=True):\n",
    "        \"\"\" Fit polynomial function to properties of object\n",
    "\n",
    "        Args: \n",
    "            x_property : name of property\n",
    "            y_property : name of property\n",
    "            degree (_int_) : degree of polynomial\n",
    "            norm (_int_) : degree of norm used to compute residuals, Default=2 \n",
    "            print_eq (_bool_) : determines if the equation of the fitted polynomial is printed\n",
    "\n",
    "        Prints:\n",
    "            Coefficient of polynomial fit\n",
    "        Returns:\n",
    "            dict : dictionary with fitted polynomial, name of the variables use for the fit and goodness of fit metrics\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        x=getattr(self,x_property)\n",
    "        if y_property =='time':  # we want to use decimal time for the fit\n",
    "            y_property='decimal_time'\n",
    "        y=getattr(self,y_property)\n",
    "\n",
    "        #print(x,y)\n",
    "\n",
    "        coefs=np.polyfit(x,y,degree)\n",
    "\n",
    "        \n",
    "        polynomial=np.poly1d(coefs)\n",
    "        \n",
    "        if print_eq:\n",
    "            print(polynomial)\n",
    "            \n",
    "        # Godness of fit\n",
    "        y_predict=polynomial(x)\n",
    "        residuals=y-y_predict\n",
    "        norm=np.linalg.norm(residuals,norm_order)  \n",
    "\n",
    "        # this metrics are not generilzed for higher order norms, they simply are the traditional metrics\n",
    "        ss_res=np.sum(residuals**2)\n",
    "        ss_tot=np.sum((y-np.mean(y))**2)\n",
    "\n",
    "        r2=1-(ss_res/ss_tot)\n",
    "\n",
    "        rmse=np.sqrt(np.mean((y-y_predict)**2))\n",
    "        nrmse=rmse/(np.max(y)-np.min(y))\n",
    "\n",
    "        n=len(y)  # number of points\n",
    "        k=degree # how many coef are we estimating\n",
    "        R2=1-((1-r2)*(n-1))/(n-k-1)\n",
    "        \n",
    "        gofs={f'{norm_order:}th norm':round(norm,4),'r2':round(r2,4),'R2':round(R2,4),'RMSE':round(rmse,4),'normalized RMSE':round(nrmse,4)}\n",
    "\n",
    "        return {'Poly fit coefficients':polynomial,'(x,y)=':[x_property,y_property],'gofs metrics':gofs}\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def predict(self,variable,new_x):\n",
    "        \"\"\"\n",
    "        Uses the fit associated with property x  to predict y based on new value of x\n",
    "\n",
    "        Args\n",
    "            self.fit(_numpy.poly1d_) attribute object with the choosen fit\n",
    "            new_x:(_int_) value use to predict\n",
    "            name(_str_): what are we predicting? \n",
    "        Return\n",
    "            y_predict(int): predicted value\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        if self.check_property(variable): \n",
    "            fit=getattr(self,('fit_'+str(variable)))\n",
    "        \n",
    "            fit_coefs=fit['Poly fit coefficients']\n",
    "            predicted_y=fit_coefs(new_x)\n",
    "            \n",
    "            return {'(x,y)': fit['(x,y)='],'x_hat':new_x,'y_hat':round(predicted_y,4)}\n",
    "        else:\n",
    "            raise AttributeError(f\"Varieble '{variable}' is not part of the predicted variables\")\n",
    "    \n",
    "    \n",
    "    def check_property(self,prop_name):\n",
    "        \"\"\"\n",
    "        simple method that check if a fit corresponding to that variable exists\n",
    "        \"\"\"\n",
    "        if not hasattr(self,prop_name):\n",
    "            raise AttributeError(f'variable \"{prop_name}\" not part of the model')\n",
    "        else: \n",
    "            return True\n",
    "        \n",
    "    def get_predicted_day(self,year):\n",
    "        \"\"\"\n",
    "        Assign the predicted date of break up related to `.fit_day_of_break_up` and the chosen year \n",
    "        Args:\n",
    "        year(_int_): year for which the prediction will be made\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if there are not fit associated to the predicted date, the method cannot get the prediction\n",
    "        Return:\n",
    "            gets predicted day of break up (day_of_year)\n",
    "        \"\"\"\n",
    "        if self.fit_day_of_year:\n",
    "            self._predicted_day_of_break_up=self.predict(self._predicted_day_of_break_up,year)\n",
    "          #  self.prediction=pd.to_datetime(f\"{self.fit_day_of_year['yhat']}-{self.fit_time['yhat']}\",format='%Y-%j')\n",
    "        else: \n",
    "            raise ValueError(\"No predicted time of break up  has been made or assign\")\n",
    "        \n",
    "    def get_predicted_time(self,year):\n",
    "        \"\"\"\n",
    "        Assign the predicted time of break up related to `.fit_time` and the chosen year \n",
    "        Args:\n",
    "        year(_int_): year for which the prediction will be made\n",
    "        Raises:\n",
    "            ValueError: if there are not fit associated to the predicted time, the method cannot get the prediction\n",
    "        Returns:\n",
    "            gets predicted time of break up ( ans transform from decimal time to hexadecimal)\n",
    "        \"\"\"\n",
    "        if self.fit_time:\n",
    "            self._predicted_time_of_break_up=decimal_time(self.predict(self._predicted_time_of_break_up,year),direction='to_hexadecimal')\n",
    "        \n",
    "        else: \n",
    "            raise ValueError(\"No predicted time of break up  has been made or assign\")\n",
    "    def get_prediction(self,year):\n",
    "        \"\"\"\n",
    "         Get the predicted date(day of year) and time associated with the year\n",
    "\n",
    "         The predicted date and time could have been set by the .get_predicted...  or assigned manually as they are properties of the class\n",
    "        Args:\n",
    "            year (_int_): \n",
    "        \"\"\"\n",
    "        if self.predicted_day_of_break_up and self.predicted_time_of_break_up:\n",
    "            # we are re-getting value just to make sure they correspond to the lattest assigned values\n",
    "            day=self.get_predicted_day(self,year)\n",
    "            time=self.get_predicted_time(self,year)\n",
    "            self.prediction=pd.to_datetime(f\"{self.predicted_day_of_break_up}-{self.predicted_time_of_break_up}\",format='%Y-%j')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOP  & Simple models for ice break up\n",
    "An effective way to create and use python model is by using and Object Oriented Programming approach, in our case we will use the class `IceModel` to construct different models by instancing an object of the class.\n",
    "\n",
    "#### Preprocessing\n",
    "In part 1 of this interactive textbook you familiarized yourself with the **Nenana Ice Classic**  got introduce to a `DataFrame` containing environmental variables that may help to predict the break up, and learned some basic preprocessing techniques.\n",
    "\n",
    "For the moment let just consider the data associated only with the past break up dates, information that is stored in `'../data/BreakUpTimes.csv'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/BreakUpTimes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# loading the file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ice_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../data/BreakUpTimes.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\iceclassic\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\iceclassic\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\iceclassic\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\iceclassic\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\gabri\\anaconda3\\envs\\iceclassic\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/BreakUpTimes.csv'"
     ]
    }
   ],
   "source": [
    "# loading the file\n",
    "ice_data = pd.read_csv('../../data/BreakUpTimes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iceclassic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
