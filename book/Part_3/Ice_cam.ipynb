{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gif/Video maker for we scrapping snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "snapshot_dir = 'nw/'\n",
    "\n",
    "# List image files in the directory\n",
    "image_files = sorted([snapshot_dir + f for f in os.listdir(snapshot_dir) if f.endswith('.jpg')])\n",
    "\n",
    "# Check if there are any image files\n",
    "if not image_files:\n",
    "    print(f\"Error: No image files found in '{snapshot_dir}'.\")\n",
    "    exit()\n",
    "\n",
    "# Read the first image to get dimensions\n",
    "first_image = cv2.imread(image_files[0])\n",
    "if first_image is None:\n",
    "    print(f\"Error: Unable to read image file '{image_files[0]}'.\")\n",
    "    exit()\n",
    "\n",
    "height, width, _ = first_image.shape\n",
    "\n",
    "output_video = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'XVID'), 60, (width, height))  # FPS and dimensions of frame\n",
    "\n",
    "# Iterate through image files and add write the frame\n",
    "for image_file in image_files:\n",
    "    frame = cv2.imread(image_file)\n",
    "    if frame is None:\n",
    "        print(f\"Error: Unable to read image file '{image_file}'. Skipping.\")\n",
    "        continue\n",
    "    output_video.write(frame)\n",
    "\n",
    "# Release video writer object\n",
    "output_video.release()\n",
    "\n",
    "print(\"Video created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the video\n",
    "video_path = 'output.avi'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Parameters for Shi-Tomasi corner detection\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.65, minDistance=10, blockSize=10)\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=4, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "# Read the first frame\n",
    "ret, prev_frame = cap.read()\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Get the dimensions of the frame\n",
    "height, width = prev_gray.shape\n",
    "\n",
    "# Define the region of interest (lower half of the image)\n",
    "roi = (0, height // 2, width, height // 2)\n",
    "\n",
    "# Detect corners in the first frame (only in the lower half)\n",
    "prev_points = cv2.goodFeaturesToTrack(prev_gray[roi[1]:roi[1]+roi[3], roi[0]:roi[0]+roi[2]], mask=None, **feature_params)\n",
    "prev_points += np.array([roi[0], roi[1]]).reshape(1, 1, 2)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "while True:\n",
    "    # Read the next frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate optical flow\n",
    "    next_points, status, _ = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prev_points, None, **lk_params)\n",
    "    \n",
    "    # Select good points\n",
    "    good_new = next_points[status == 1]\n",
    "    good_old = prev_points[status == 1]\n",
    "    \n",
    "    # Draw tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel().astype(int)\n",
    "        c, d = old.ravel().astype(int)\n",
    "        mask = cv2.line(mask, (a, b), (c, d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame, (a, b), 5, color[i].tolist(), -1)\n",
    "    \n",
    "    # Overlay the tracks on the frame\n",
    "    img = cv2.add(frame, mask)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', img)\n",
    "    \n",
    "    # Update previous points and previous frame\n",
    "    prev_gray = frame_gray.copy()\n",
    "    prev_points = good_new.reshape(-1, 1, 2)\n",
    "    \n",
    "    # Exit on 'q' press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18700\\3373584948.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Select good points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mgood_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_points\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mgood_old\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_points\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the video\n",
    "video_path = 'output.avi'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Parameters for Shi-Tomasi corner detection\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.80, minDistance=50, blockSize=20)\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=4, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "# Read the first frame\n",
    "ret, prev_frame = cap.read()\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect corners in the first frame\n",
    "prev_points = cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "while True:\n",
    "    # Read the next frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate optical flow\n",
    "    next_points, status, _ = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prev_points, None, **lk_params)\n",
    "    \n",
    "    # Select good points\n",
    "    good_new = next_points[status == 1]\n",
    "    good_old = prev_points[status == 1]\n",
    "    \n",
    "    # Draw tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel().astype(int)\n",
    "        c, d = old.ravel().astype(int)\n",
    "        mask = cv2.line(mask, (a, b), (c, d), color[i].tolist(), 1)\n",
    "        frame = cv2.circle(frame, (a, b), 5, color[i].tolist(), -1)\n",
    "    \n",
    "    # Overlay the tracks on the frame\n",
    "    img = cv2.add(frame, mask)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', img)\n",
    "    \n",
    "    # Update previous points and previous frame\n",
    "    prev_gray = frame_gray.copy()\n",
    "    prev_points = good_new.reshape(-1, 1, 2)\n",
    "    \n",
    "    # Exit on 'q' press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to detect melting areas in a frame\n",
    "def detect_melting_areas(frame, mask):\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply mask to focus only on the lower half\n",
    "    masked_gray = cv2.bitwise_and(gray, gray, mask=mask)\n",
    "    \n",
    "    # Apply thresholding to identify melting areas\n",
    "    _, thresh = cv2.threshold(masked_gray, 150, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Draw contours on original frame\n",
    "    melting_areas = frame.copy()\n",
    "    cv2.drawContours(melting_areas, contours, -1, (255, 0, 0), 1)\n",
    "    \n",
    "    return melting_areas\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture('output.avi')\n",
    "\n",
    "# Create a mask to focus only on the lower half of the frame\n",
    "height, width = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "mask = np.zeros((height, width), dtype=np.uint8)\n",
    "mask[height//2:,:] = 255\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Detect melting areas in the current frame\n",
    "    melting_areas_frame = detect_melting_areas(frame, mask)\n",
    "    \n",
    "    # Display the result\n",
    "    cv2.imshow('Melting Areas', melting_areas_frame)\n",
    "    \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Function to detect melting areas in a frame\n",
    "def detect_melting_areas(frame, mask):\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply mask to focus only on the lower half\n",
    "    masked_gray = cv2.bitwise_and(gray, gray, mask=mask)\n",
    "    \n",
    "    # Apply thresholding to identify melting areas\n",
    "    _, thresh = cv2.threshold(masked_gray, 150, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Draw contours on original frame\n",
    "    melting_areas = frame.copy()\n",
    "    cv2.drawContours(melting_areas, contours, -1, (255, 0, 0), 1)\n",
    "    \n",
    "    return melting_areas\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture('output.avi')\n",
    "\n",
    "# Create a mask to focus only on the lower half of the frame\n",
    "height, width = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "mask = np.zeros((height, width), dtype=np.uint8)\n",
    "mask[height//2:,:] = 255\n",
    "\n",
    "# Set desired FPS for processing\n",
    "desired_fps = 900\n",
    "\n",
    "# Get the frame rate of the video\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Calculate the time interval between frames for the desired FPS\n",
    "frame_interval = 1 / desired_fps\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read a frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Detect melting areas in the current frame\n",
    "    melting_areas_frame = detect_melting_areas(frame, mask)\n",
    "    \n",
    "    # Display the result\n",
    "    cv2.imshow('Melting Areas', melting_areas_frame)\n",
    "    \n",
    "    # Wait for the calculated time interval between frames\n",
    "    time.sleep(frame_interval)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'TrackerMOSSE_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4100\\1242292404.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Initialize tracker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtracker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrackerMOSSE_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Read the first frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'TrackerMOSSE_create'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the video\n",
    "video_path = 'output.avi'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Initialize tracker\n",
    "tracker = cv2.TrackerMOSSE_create()\n",
    "\n",
    "# Read the first frame\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Error: Unable to read the video\")\n",
    "    exit()\n",
    "\n",
    "# Select ROI (Region of Interest) for tracking\n",
    "bbox = cv2.selectROI(\"Select Object to Track\", frame, False)\n",
    "tracker.init(frame, bbox)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Update tracker\n",
    "    ret, bbox = tracker.update(frame)\n",
    "\n",
    "    # Draw bounding box\n",
    "    if ret:\n",
    "        # Tracking success\n",
    "        (x, y, w, h) = [int(v) for v in bbox]\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    else:\n",
    "        # Tracking failure\n",
    "        cv2.putText(frame, \"Tracking failure detected\", (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "\n",
    "    # Display frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Function to detect melting areas in a frame\n",
    "def detect_melting_areas(frame, mask):\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply mask to focus only on the lower half\n",
    "    masked_gray = cv2.bitwise_and(gray, gray, mask=mask)\n",
    "    \n",
    "    # Apply thresholding to identify melting areas\n",
    "    _, thresh = cv2.threshold(masked_gray, 150, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Draw contours on original frame\n",
    "    melting_areas = frame.copy()\n",
    "    cv2.drawContours(melting_areas, contours, -1, (255, 0, 0), 1)\n",
    "    \n",
    "    return melting_areas\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture('output.avi')\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Create VideoWriter object to save the processed video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Choose the codec (codec might vary based on the operating system)\n",
    "out = cv2.VideoWriter('output_with_traces.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Create a mask to focus only on the lower half of the frame\n",
    "mask = np.zeros((frame_height, frame_width), dtype=np.uint8)\n",
    "mask[frame_height//2:,:] = 255\n",
    "\n",
    "# Set desired FPS for processing\n",
    "desired_fps = 900\n",
    "\n",
    "# Calculate the time interval between frames for the desired FPS\n",
    "frame_interval = 1 / desired_fps\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read a frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Detect melting areas in the current frame\n",
    "    melting_areas_frame = detect_melting_areas(frame, mask)\n",
    "    \n",
    "    # Write the frame with processing traces to the output video\n",
    "    out.write(melting_areas_frame)\n",
    "    \n",
    "    # Display the result\n",
    "    cv2.imshow('Melting Areas', melting_areas_frame)\n",
    "    \n",
    "    # Wait for the calculated time interval between frames\n",
    "    time.sleep(frame_interval)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video capture and close windows\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
