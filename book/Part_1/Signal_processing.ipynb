{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Processing\n",
    "The plots created in the last section show a strong annual harmonic component. Lets, identify this components, subtract them from the signal and the re-plot to see if there is any transannual trend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from funciones import*\n",
    "import matplotlib.pyplot as plt\n",
    "import funciones\n",
    "\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "Data=pd.read_csv(\"../../data/Time_series_DATA.txt\",skiprows=149,index_col=0,sep='\\t')\n",
    "Data.index = pd.to_datetime(Data.index, format=\"%Y-%m-%d\")\n",
    "explore_contents(Data,opt={'Sparsity':True,'Info':True,'Time History': False})\n",
    "#Data=Data.drop(columns=['Days since start of year','Days until break up','Noisy predicted ice thickness [m]'])\n",
    "#Data=pd.read_csv('https://raw.githubusercontent.com/iceclassic/sandbox/main/Data/Time_series_DATA.txt',index_col=0,skiprows=149)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationary Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets compute the mean\n",
    "\n",
    "# de trend de data\n",
    "\n",
    "\n",
    "# plot Spectrogram\n",
    "\n",
    "# plot Autocorrelation formula\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Spectral density\n",
    "A simple way to estimate the Power Spectral Density (PSD) of signal is using the [Welch method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html#id1).\n",
    "> do we explain the theory behind the method?\n",
    "\n",
    ":::{card} Exercise 1\n",
    "\n",
    "Read the documentation for `compute_and_plot_psd()` function from the ice_classic package and estimate te PSD for all columns\n",
    "Â¿ Do all the variable experience the same seasonal behavior? Is there any multiyear harmonic?\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=compute_and_plot_psd(Data,plot_period=False)\t\n",
    "\n",
    "# given the frequency of our signal, using the period (T) instead of the frequency (1/F) might be better \n",
    "PSD_info=compute_and_plot_psd(Data,plot_period=True,find_peaks_kwargs={\"distance\":100,\"threshold\":10})\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last figures, multiple peaks can be observed with the most prominent being the associated with a period of  350-370, which is  expected as is represent the yearly variation.\n",
    "\n",
    "One common way to identify the peak of PSD is to use [`find_peaks()`](https://docs.scipy.org/doc/scipy//reference/generated/scipy.signal.find_peaks.html) from  `scipy`.The function `compute_and_plot_psd()` uses internally this function to find the peaks of each column, and saves them in a dictionary. \n",
    "\n",
    "\n",
    "::{card} Exercise 2\n",
    "Extract the peak of each column and compare them.\n",
    "```{admonition} Tips/Help\n",
    ":class: tip, dropdown\n",
    "Look-up the documentation of `[find_peaks]`(https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks.html). Considering what you expect the peaks to look like, change the values of `prominence`, `distance` and or `threshold` to refine the search for peaks\n",
    "```\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, psd_info in PSD_info.items():\n",
    "    peak_periods =np.round(psd_info['peak_periods']).astype(int) \n",
    "    \n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"Peak Periods: {peak_periods}\\n\")\n",
    "\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(PSD_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another issue wiht the plot above is that we can observe a lot of high-frequency component, which are most likely associate with noise.\n",
    "Lets apply a low-pass filter, that block higher frequencies and lets *low frequencies pass* and re-plot.\n",
    "\n",
    "> show that rolling mean can be thougth of as a low pass filter?\n",
    "\n",
    ":::{card} Exercise 4\n",
    "Use the same function as before, but consider the argument chagninf the default of  `apply_filter`, `max_allowed_freq`and `filter_order`\n",
    ":::\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=compute_and_plot_psd(Data,plot_period=False,find_peaks_kwargs={\"distance\":100,\"threshold\":10,\"height\":1e-2},apply_filter=True,max_allowed_freq=1/14,filter_order=4)\n",
    "PSD_info=compute_and_plot_psd(Data,plot_period=True,find_peaks_kwargs={\"distance\":100,\"threshold\":10,\"height\":1e-2},apply_filter=True,max_allowed_freq=1/30,filter_order=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, psd_info in PSD_info.items():\n",
    "    peak_periods =np.round(psd_info['peak_periods']).astype(int) \n",
    "    \n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"Peak Periods: {peak_periods}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> put here plot of historic seasonality+ harmonic identified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_harmonics_with_amplitude(index, peak_periods, peak_psd_values, num_harmonics=1):\n",
    "    \"\"\"Generate harmonic components based on peak periods and their amplitudes.\"\"\"\n",
    "    harmonics = np.zeros(len(index))\n",
    "    \n",
    "    for period, amplitude in zip(peak_periods, peak_psd_values):\n",
    "        frequency = 2 * np.pi / period\n",
    "        for n in range(1, num_harmonics + 1):\n",
    "            harmonics += amplitude * np.sin(n * frequency * np.arange(len(index)))\n",
    "    \n",
    "    return harmonics\n",
    "def compute_residuals(df, psd_info, num_harmonics=1):\n",
    "    \"\"\"Compute residuals by subtracting harmonic components from data using peak information.\"\"\"\n",
    "    residuals_df = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    for col, info in psd_info.items():\n",
    "        if col in df.columns:\n",
    "            peak_periods = np.round(info['peak_periods']).astype(int)\n",
    "            peak_psd_values = info['peak_psd_values']\n",
    "            \n",
    "            harmonics = generate_harmonics_with_amplitude(df.index, peak_periods, peak_psd_values, num_harmonics)\n",
    "            residuals_df[col] = df[col] - harmonics\n",
    "\n",
    "    return residuals_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compute residuals\n",
    "residuals_df = compute_residuals(Data, psd_info, num_harmonics=3)\n",
    "explore_contents(residuals_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iceclassic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
